{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":14322218,"sourceType":"datasetVersion","datasetId":9143064},{"sourceId":14322803,"sourceType":"datasetVersion","datasetId":9143488},{"sourceId":14323540,"sourceType":"datasetVersion","datasetId":9144043}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Generate Drawings from Checkpoint and Zip Results\n\nThis notebook loads a trained checkpoint, generates drawings from all image files, and creates a zip file with the results.\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\nimport os\nimport zipfile\nfrom tqdm import tqdm\nimport numpy as np\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:28:53.413704Z","iopub.execute_input":"2025-12-28T17:28:53.414034Z","iopub.status.idle":"2025-12-28T17:29:04.693434Z","shell.execute_reply.started":"2025-12-28T17:28:53.414005Z","shell.execute_reply":"2025-12-28T17:29:04.692368Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## Model Architecture (from original notebook)\n","metadata":{}},{"cell_type":"code","source":"class Downblock(nn.Module):\n    def __init__(\n        self,\n        # dims\n        in_ch, out_ch,\n        # conv\n        kernel_size=3, stride=1, padding=0, use_bias=True,\n        # norm\n        apply_norm=True, use_inst_norm=True,\n        # activation\n        activation='relu',\n        # dropout\n        dropout_ratio=0.0\n        ):\n        super().__init__()\n        layers = []\n\n        # 1. conv (better padding)\n        layers.append(nn.ReflectionPad2d(padding))\n        layers.append(nn.Conv2d(\n            in_ch, out_ch,\n            kernel_size, stride, 0,\n            bias=use_bias,\n            padding_mode='reflect'\n        ))\n\n        # 2. norm\n        if apply_norm:\n            if use_inst_norm:\n                layers.append(nn.InstanceNorm2d(out_ch))\n            else:\n                layers.append(nn.BatchNorm2d(out_ch))\n\n        # 3. activation\n        if activation != '':\n            if activation == 'gelu':\n                layers.append(nn.GELU())\n            elif activation == 'leaky':\n                layers.append(nn.LeakyReLU(negative_slope=0.2, inplace=True))\n            else:\n                layers.append(nn.ReLU(inplace=True))\n\n        # 4. dropout\n        if dropout_ratio > 0.0:\n            layers.append(nn.Dropout(dropout_ratio))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:29:04.695452Z","iopub.execute_input":"2025-12-28T17:29:04.695898Z","iopub.status.idle":"2025-12-28T17:29:04.705809Z","shell.execute_reply.started":"2025-12-28T17:29:04.695867Z","shell.execute_reply":"2025-12-28T17:29:04.704769Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class Upblock(nn.Module):\n    def __init__(\n        self,\n        # dims\n        in_ch, out_ch,\n        # conv transpose\n        kernel_size=3, stride=2, padding=1, output_padding=1, use_bias=True,\n        # norm\n        apply_norm=True, use_inst_norm=True,\n        # activation\n        activation='gelu',\n        # dropout\n        dropout_ratio=0.5,\n        # UNet specific\n        is_pre_activation=False\n        ):\n        super().__init__()\n        layers = []\n\n        # 1. conv transpose\n        layers.append(nn.ConvTranspose2d(\n            in_ch, out_ch,\n            kernel_size=kernel_size,\n            stride=stride,\n            padding=padding,\n            output_padding=output_padding,\n            bias=use_bias\n        ))\n\n        # 1. upsample + conv (checkerboard fix)\n        # layers.append(nn.Upsample(scale_factor=stride, mode='bilinear'))\n        # layers.append(nn.ReflectionPad2d(padding))\n        # layers.append(nn.Conv2d(\n        #     in_ch, out_ch,\n        #     kernel_size=kernel_size,\n        #     stride=1,\n        #     padding=0,\n        #     bias=use_bias\n        # ))\n\n\n        # 2. norm\n        if apply_norm:\n            if use_inst_norm:\n                layers.append(nn.InstanceNorm2d(out_ch))\n            else:\n                layers.append(nn.BatchNorm2d(out_ch))\n\n        # 3. activation\n        if activation != '':\n            if activation == 'gelu':\n                act = nn.GELU()\n            else:\n                act = nn.ReLU(inplace=True)\n\n            if is_pre_activation:\n                layers.insert(1, act)\n            else:\n                layers.append(act)\n\n        # 4. Dropout\n        if dropout_ratio > 0.0:\n            layers.append(nn.Dropout(dropout_ratio))\n\n        self.model = nn.Sequential(*layers)\n\n    def forward(self, x):\n        return self.model(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:29:04.707044Z","iopub.execute_input":"2025-12-28T17:29:04.707311Z","iopub.status.idle":"2025-12-28T17:29:04.728204Z","shell.execute_reply.started":"2025-12-28T17:29:04.707284Z","shell.execute_reply":"2025-12-28T17:29:04.727213Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"class UNetGenerator(nn.Module):\n    def __init__(self, in_ch=3, out_ch=3, num_downs=8, dropout=0.5):\n        super().__init__()\n\n        self.num_downs = num_downs\n\n        base_ch = 64\n\n        # Encoder/Decoder channel progression\n        enc_in_chs = [in_ch] + [base_ch * min(2**i, 8) for i in range(num_downs-1)]\n        enc_out_chs = [base_ch * min(2**i, 8) for i in range(num_downs)]\n\n        dec_in_chs = [enc_out_chs[::-1][0]] + [c * 2 for c in enc_out_chs[::-1][1:]]\n        dec_out_chs = enc_in_chs[::-1]\n\n        # Encoder\n        self.encoder = nn.ModuleList()\n        for i in range(num_downs):\n            use_norm = i > 0 and i < num_downs - 1 # No norm in first layer or last layer (bottleneck)\n            activation = 'leaky' if i != num_downs - 1 else 'relu'\n            self.encoder.append(\n                Downblock(\n                    in_ch=enc_in_chs[i], out_ch=enc_out_chs[i],\n                    kernel_size=4, stride=2, padding=1, use_bias=False,\n                    apply_norm=use_norm, use_inst_norm=True,\n                    activation=activation,\n                    dropout_ratio=0.0\n                )\n            )\n\n        # Decoder\n        self.decoder = nn.ModuleList()\n        for i in range(num_downs):\n            use_dropout = i < 3 # First 3 decoder layers have dropout\n            apply_norm = i != num_downs - 1 # No norm in final layer\n            activation = '' if i == num_downs - 1 else 'relu' # No activation in final layer\n            self.decoder.append(\n                Upblock(\n                    in_ch=dec_in_chs[i], out_ch=dec_out_chs[i],\n                    kernel_size=4, stride=2, padding=1, output_padding=0, use_bias=False,\n                    apply_norm=apply_norm, use_inst_norm=True,\n                    activation=activation,\n                    dropout_ratio=dropout if use_dropout else 0.0,\n                    is_pre_activation=True\n                )\n            )\n\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        # Encoder output for skip connections\n        encoder_outputs = []\n\n        # Encoder forward pass\n        current = x\n        for encoder_block in self.encoder:\n            current = encoder_block(current)\n            encoder_outputs.append(current)\n\n        # Decoder forward pass with skip connections\n        for i, decoder_block in enumerate(self.decoder):\n            current = decoder_block(current)\n            skip_idx = len(encoder_outputs) - 1 - i - 1\n            if skip_idx >= 0:\n                current = torch.cat([current, encoder_outputs[skip_idx]], dim=1)\n\n        # Tanh activation at the end\n        output = self.tanh(current)\n\n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:29:04.729290Z","iopub.execute_input":"2025-12-28T17:29:04.729588Z","iopub.status.idle":"2025-12-28T17:29:04.748762Z","shell.execute_reply.started":"2025-12-28T17:29:04.729553Z","shell.execute_reply":"2025-12-28T17:29:04.747464Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"## Configuration\n","metadata":{}},{"cell_type":"code","source":"# Path to the checkpoint file\nCHECKPOINT_PATH = \"/kaggle/input/final-2/cyclegan_final (1).pth\"  # Update this to your checkpoint path\n\n# Directory containing input images\n# INPUT_IMAGE_DIR = \"/kaggle/input/gan-getting-started/photo_jpg\"  # Update this to your image directory\nINPUT_IMAGE_DIR = \"/kaggle/input/gan-getting-started/photo_jpg\"  # Update this to your image directory\n\n# Output zip file name\nZIP_FILE_NAME = \"/kaggle/working/images.zip\"\n\n# Image size (should match training size)\nIMAGE_SIZE = (256, 256)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:29:04.750090Z","iopub.execute_input":"2025-12-28T17:29:04.750458Z","iopub.status.idle":"2025-12-28T17:29:04.770766Z","shell.execute_reply.started":"2025-12-28T17:29:04.750420Z","shell.execute_reply":"2025-12-28T17:29:04.769748Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"!ls /kaggle/input/","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:29:04.771915Z","iopub.execute_input":"2025-12-28T17:29:04.772174Z","iopub.status.idle":"2025-12-28T17:29:04.916147Z","shell.execute_reply.started":"2025-12-28T17:29:04.772149Z","shell.execute_reply":"2025-12-28T17:29:04.914805Z"}},"outputs":[{"name":"stdout","text":"final-1  final-2  gan-getting-started  test-checkpoint\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!ls /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:29:04.919241Z","iopub.execute_input":"2025-12-28T17:29:04.919796Z","iopub.status.idle":"2025-12-28T17:29:05.050264Z","shell.execute_reply.started":"2025-12-28T17:29:04.919729Z","shell.execute_reply":"2025-12-28T17:29:05.049120Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## Load Checkpoint and Initialize Model\n","metadata":{}},{"cell_type":"code","source":"def load_checkpoint(ckpt_path, map_location=None):\n    \"\"\"Load checkpoint from file\"\"\"\n    ckpt = torch.load(ckpt_path, map_location=map_location)\n    print(f'[*] Loading checkpoint from {ckpt_path} succeed!')\n    return ckpt\n\n# Initialize generator\ngenerator = UNetGenerator(in_ch=3, out_ch=3, num_downs=8, dropout=0.5).to(device)\n\n# Load checkpoint\ncheckpoint = load_checkpoint(CHECKPOINT_PATH, map_location=device)\n\n# Load generator weights\nif 'g_ptm' in checkpoint:\n    generator.load_state_dict(checkpoint['g_ptm'])\n    print(\"Generator weights loaded successfully!\")\nelse:\n    print(\"Warning: 'g_ptm' key not found in checkpoint. Trying direct load...\")\n    generator.load_state_dict(checkpoint)\n\n# Set to evaluation mode\ngenerator.eval()\nprint(\"Model ready for inference!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:29:05.051853Z","iopub.execute_input":"2025-12-28T17:29:05.052169Z","iopub.status.idle":"2025-12-28T17:29:09.060882Z","shell.execute_reply.started":"2025-12-28T17:29:05.052135Z","shell.execute_reply":"2025-12-28T17:29:09.059871Z"}},"outputs":[{"name":"stdout","text":"[*] Loading checkpoint from /kaggle/input/final-2/cyclegan_final (1).pth succeed!\nGenerator weights loaded successfully!\nModel ready for inference!\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## Generate Drawings from All Images\n","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/*.jpg","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:31:38.426605Z","iopub.execute_input":"2025-12-28T17:31:38.426946Z","iopub.status.idle":"2025-12-28T17:31:38.568276Z","shell.execute_reply.started":"2025-12-28T17:31:38.426920Z","shell.execute_reply":"2025-12-28T17:31:38.566957Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Define image transform (same as training)\ntransform = transforms.Compose([\n    transforms.Resize(IMAGE_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\n# Get all image files\nimage_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')\nimage_files = [f for f in os.listdir(INPUT_IMAGE_DIR) \n               if f.lower().endswith(image_extensions)]\n\nprint(f\"Found {len(image_files)} image files to process\")\n\n# Process each image\ngenerated_files = []\nwith torch.no_grad():\n    for img_file in tqdm(image_files, desc=\"Generating drawings\"):\n        try:\n            # Load and preprocess image\n            img_path = os.path.join(INPUT_IMAGE_DIR, img_file)\n            img = Image.open(img_path).convert('RGB')\n            img_tensor = transform(img).unsqueeze(0).to(device)\n            \n            # Generate drawing\n            generated = generator(img_tensor)\n            \n            # Convert back to PIL Image\n            generated = generated.squeeze(0).cpu()\n            # Denormalize from [-1, 1] to [0, 1]\n            generated = generated * 0.5 + 0.5\n            generated = torch.clamp(generated, 0.0, 1.0)\n            \n            # Convert to PIL and save\n            to_pil = transforms.ToPILImage()\n            generated_pil = to_pil(generated)\n            \n            # Save with same name as input\n            output_path = img_file\n            generated_pil.save(output_path)\n            generated_files.append(output_path)\n            \n        except Exception as e:\n            print(f\"Error processing {img_file}: {str(e)}\")\n            continue\n\nprint(f\"\\nGenerated {len(generated_files)} drawings successfully!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T17:31:38.928595Z","iopub.execute_input":"2025-12-28T17:31:38.928972Z","iopub.status.idle":"2025-12-28T17:31:45.748426Z","shell.execute_reply.started":"2025-12-28T17:31:38.928934Z","shell.execute_reply":"2025-12-28T17:31:45.747150Z"}},"outputs":[{"name":"stdout","text":"Found 7038 image files to process\n","output_type":"stream"},{"name":"stderr","text":"Generating drawings:   0%|          | 25/7038 [00:06<31:19,  3.73it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/698451405.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Generate drawing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mgenerated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Convert back to PIL Image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/1853003450.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Decoder forward pass with skip connections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             \u001b[0mcurrent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m             \u001b[0mskip_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mskip_idx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/4159412882.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         )\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m   1162\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":10},{"cell_type":"markdown","source":"## Zip Generated Images\n","metadata":{}},{"cell_type":"code","source":"# Create zip file\nprint(f\"Creating zip file: {ZIP_FILE_NAME}\")\nwith zipfile.ZipFile(ZIP_FILE_NAME, 'w', zipfile.ZIP_DEFLATED) as zipf:\n    for file_path in tqdm(generated_files, desc=\"Adding files to zip\"):\n        # Get just the filename for the zip archive\n        arcname = os.path.basename(file_path)\n        zipf.write(file_path, arcname)\n\n# Get zip file size\nzip_size = os.path.getsize(ZIP_FILE_NAME) / (1024 * 1024)  # Size in MB\nprint(f\"\\nZip file created successfully!\")\nprint(f\"Zip file: {ZIP_FILE_NAME}\")\nprint(f\"Zip file size: {zip_size:.2f} MB\")\nprint(f\"Number of files in zip: {len(generated_files)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-28T16:30:04.848450Z","iopub.execute_input":"2025-12-28T16:30:04.848866Z","iopub.status.idle":"2025-12-28T16:30:08.350595Z","shell.execute_reply.started":"2025-12-28T16:30:04.848835Z","shell.execute_reply":"2025-12-28T16:30:08.349773Z"}},"outputs":[{"name":"stdout","text":"Creating zip file: /kaggle/working/images.zip\n","output_type":"stream"},{"name":"stderr","text":"Adding files to zip: 100%|██████████| 7038/7038 [00:03<00:00, 2032.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nZip file created successfully!\nZip file: /kaggle/working/images.zip\nZip file size: 94.86 MB\nNumber of files in zip: 7038\n","output_type":"stream"}],"execution_count":60},{"cell_type":"markdown","source":"## Optional: Clean up temporary output directory\n\nUncomment the cell below if you want to remove the temporary output directory after zipping.\n","metadata":{}},{"cell_type":"code","source":"# Uncomment to remove the temporary output directory\n# import shutil\n# if os.path.exists(OUTPUT_DIR):\n#     shutil.rmtree(OUTPUT_DIR)\n#     print(f\"Removed temporary directory: {OUTPUT_DIR}\")\n","metadata":{},"outputs":[],"execution_count":null}]}